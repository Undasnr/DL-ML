{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW4UTzoVwMWVkB3Z88ZvmR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Undasnr/DL-ML/blob/main/Ronny_Credit_Information_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confirmation of competition content and creating a baseline model**\n",
        "\n",
        "**Goal**: Predict the probability that a loan applicant will default on their loan.\n",
        "\n",
        "**Type of Task**: Binary classification\n",
        "\n",
        "TARGET = 1: Applicant will have difficulty repaying\n",
        "\n",
        "TARGET = 0: Applicant will repay the loan\n",
        "\n",
        "**What to Submit to Kaggle**\n",
        "I’ll submit a CSV file with two columns:\n",
        "\n",
        "1. SK_ID_CURR: Unique ID for each applicant in the test set\n",
        "\n",
        "2. TARGET: Predicted probability of default (a float between 0 and 1)\n",
        "\n",
        "**Evaluation Metric**\n",
        "Kaggle uses Area Under the ROC Curve (AUC) to evaluate submissions.\n",
        "\n",
        "AUC measures how well my model distinguishes between defaulters and non-defaulters.\n",
        "\n",
        "Higher AUC = better model performance"
      ],
      "metadata": {
        "id": "YZA8xG62Il_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi-PKWNFFeIs",
        "outputId": "7abf7558-4076-403e-ad5d-ef9d97bae234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.6258083065422515\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Loading data\n",
        "train = pd.read_csv('application_train.csv')\n",
        "test = pd.read_csv('application_test.csv')\n",
        "\n",
        "# Selecting basic features\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'DAYS_BIRTH', 'DAYS_EMPLOYED']\n",
        "X = train[features]\n",
        "y = train['TARGET']\n",
        "X_test = test[features]\n",
        "\n",
        "# Preprocessing\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Training the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Predict\n",
        "preds = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
        "    'TARGET': preds\n",
        "})\n",
        "submission.to_csv('baseline_submission.csv', index=False)\n",
        "\n",
        "# Evaluate on train set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "val_preds = model.predict_proba(X_val)[:, 1]\n",
        "print(\"Validation AUC:\", roc_auc_score(y_val, val_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning and Verification**"
      ],
      "metadata": {
        "id": "Cp8QeMxIMVo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load training data\n",
        "train = pd.read_csv('application_train.csv')\n",
        "test = pd.read_csv('application_test.csv')\n",
        "\n",
        "print(train.shape)\n",
        "print(train[['TARGET', 'AMT_INCOME_TOTAL', 'AMT_CREDIT']].describe())\n",
        "print(train['TARGET'].value_counts(normalize=True))\n",
        "\n",
        "missing = train.isnull().sum().sort_values(ascending=False)\n",
        "print(\"Top missing features:\\n\", missing.head())\n",
        "\n",
        "# Correlation with target\n",
        "corr = train.corr(numeric_only=True)['TARGET'].sort_values(ascending=False)\n",
        "print(\"Top correlated features:\\n\", corr.head(10))\n",
        "\n",
        "# Preprocessing\n",
        "features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH']\n",
        "X = train[features]\n",
        "y = train['TARGET']\n",
        "X_test = test[features]\n",
        "\n",
        "# Impute and scale\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Splitting for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting probabilities\n",
        "val_preds = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Evaluating\n",
        "auc = roc_auc_score(y_val, val_preds)\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Creating submission file\n",
        "submission = pd.DataFrame({\n",
        "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
        "    'TARGET': test_preds\n",
        "})\n",
        "submission.to_csv('baseline_submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcRamjM5Mdfo",
        "outputId": "819480ea-f1cb-4c5c-a4f7-70148573a969"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(242712, 122)\n",
            "              TARGET  AMT_INCOME_TOTAL    AMT_CREDIT\n",
            "count  242712.000000      2.427120e+05  2.427110e+05\n",
            "mean        0.080973      1.688283e+05  5.986425e+05\n",
            "std         0.272793      2.604745e+05  4.020240e+05\n",
            "min         0.000000      6.750000e+02  4.500000e+04\n",
            "25%         0.000000      1.125000e+05  2.700000e+05\n",
            "50%         0.000000      1.458000e+05  5.124465e+05\n",
            "75%         0.000000      2.025000e+05  8.086500e+05\n",
            "max         1.000000      1.170000e+08  4.050000e+06\n",
            "TARGET\n",
            "0    0.919027\n",
            "1    0.080973\n",
            "Name: proportion, dtype: float64\n",
            "Top missing features:\n",
            " COMMONAREA_AVG              169738\n",
            "COMMONAREA_MODE             169738\n",
            "COMMONAREA_MEDI             169738\n",
            "NONLIVINGAPARTMENTS_MEDI    168582\n",
            "NONLIVINGAPARTMENTS_MODE    168582\n",
            "dtype: int64\n",
            "Top correlated features:\n",
            " TARGET                         1.000000\n",
            "DAYS_BIRTH                     0.077927\n",
            "REGION_RATING_CLIENT_W_CITY    0.061065\n",
            "REGION_RATING_CLIENT           0.059101\n",
            "DAYS_LAST_PHONE_CHANGE         0.054688\n",
            "DAYS_ID_PUBLISH                0.053142\n",
            "REG_CITY_NOT_WORK_CITY         0.050954\n",
            "FLAG_EMP_PHONE                 0.045275\n",
            "FLAG_DOCUMENT_3                0.044822\n",
            "REG_CITY_NOT_LIVE_CITY         0.044167\n",
            "Name: TARGET, dtype: float64\n",
            "Validation AUC: 0.7193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estimation on test data**"
      ],
      "metadata": {
        "id": "LvLXyAGjPkGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Loading data\n",
        "train = pd.read_csv('application_train.csv')\n",
        "test = pd.read_csv('application_test.csv')\n",
        "\n",
        "# Features for baseline\n",
        "features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
        "            'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH']\n",
        "\n",
        "X = train[features]\n",
        "y = train['TARGET']\n",
        "X_test = test[features]\n",
        "\n",
        "# Impute and scale baseline features\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Polynomial features for EXT_SOURCE vars\n",
        "ext_sources_train = imputer.fit_transform(train[['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']])\n",
        "ext_sources_test = imputer.transform(test[['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']])\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
        "X_poly_train = poly.fit_transform(ext_sources_train)\n",
        "X_poly_test = poly.transform(ext_sources_test)\n",
        "\n",
        "# Converting to DataFrames with feature names\n",
        "poly_feature_names = poly.get_feature_names_out(['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3'])\n",
        "X_poly_train_df = pd.DataFrame(X_poly_train, columns=poly_feature_names, index=train.index)\n",
        "X_poly_test_df = pd.DataFrame(X_poly_test, columns=poly_feature_names, index=test.index)\n",
        "\n",
        "# Displaying interaction features\n",
        "print(\"Polynomial features shape:\", X_poly_train_df.shape)\n",
        "print(\"First 5 rows:\\n\", X_poly_train_df.head())\n",
        "\n",
        "# Merging polynomial features back into X\n",
        "X_full = pd.concat([pd.DataFrame(X_scaled, index=train.index, columns=features),\n",
        "                    X_poly_train_df], axis=1)\n",
        "X_test_full = pd.concat([pd.DataFrame(X_test_scaled, index=test.index, columns=features),\n",
        "                         X_poly_test_df], axis=1)\n",
        "\n",
        "# Training/validating Logistic Regression\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "val_preds = model.predict_proba(X_val)[:, 1]\n",
        "auc = roc_auc_score(y_val, val_preds)\n",
        "print(f\"Validation AUC with polynomial features: {auc:.4f}\")\n",
        "\n",
        "# Predicting on test set and creating submission\n",
        "test_preds = model.predict_proba(X_test_full)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
        "    'TARGET': test_preds\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"✅ Submission file saved: submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8gBacAPPqOP",
        "outputId": "e2240b3f-1a5a-4d87-d394-19fed8e72f95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial features shape: (307511, 7)\n",
            "First 5 rows:\n",
            "      1  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  EXT_SOURCE_1 EXT_SOURCE_2  \\\n",
            "0  1.0      0.083037      0.262949      0.139376                   0.021834   \n",
            "1  1.0      0.311267      0.622246      0.535276                   0.193685   \n",
            "2  1.0      0.505998      0.555912      0.729567                   0.281290   \n",
            "3  1.0      0.505998      0.650442      0.535276                   0.329122   \n",
            "4  1.0      0.505998      0.322738      0.535276                   0.163305   \n",
            "\n",
            "   EXT_SOURCE_1 EXT_SOURCE_3  EXT_SOURCE_2 EXT_SOURCE_3  \n",
            "0                   0.011573                   0.036649  \n",
            "1                   0.166614                   0.333073  \n",
            "2                   0.369159                   0.405575  \n",
            "3                   0.270849                   0.348166  \n",
            "4                   0.270849                   0.172754  \n",
            "Validation AUC with polynomial features: 0.7208\n",
            "✅ Submission file saved: submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "xll7c5RLUjCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Loading Data\n",
        "train = pd.read_csv('application_train.csv')\n",
        "test = pd.read_csv('application_test.csv')\n",
        "\n",
        "# Creating Target\n",
        "y = train['TARGET']\n",
        "train.drop(columns=['TARGET'], inplace=True)\n",
        "\n",
        "# Splitting for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(train, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Evaluating AUC\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    preds = model.predict_proba(X_val)[:, 1]\n",
        "    return roc_auc_score(y_val, preds)\n",
        "\n",
        "# Pattern 1: Basic Numeric Features\n",
        "features_1 = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'DAYS_BIRTH', 'DAYS_EMPLOYED']\n",
        "pipeline_1 = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "model_1 = pipeline_1.fit(X_train[features_1], y_train)\n",
        "auc_1 = evaluate_model(model_1, X_val[features_1], y_val)\n",
        "\n",
        "# Pattern 2: Ratio Features\n",
        "X_train = X_train.copy()\n",
        "X_val = X_val.copy()\n",
        "X_train['CREDIT_INCOME_RATIO'] = X_train['AMT_CREDIT'] / X_train['AMT_INCOME_TOTAL']\n",
        "X_train['EMPLOYED_AGE_RATIO'] = X_train['DAYS_EMPLOYED'] / X_train['DAYS_BIRTH']\n",
        "X_train['ANNUITY_INCOME_RATIO'] = X_train['AMT_ANNUITY'] / X_train['AMT_INCOME_TOTAL']\n",
        "X_val['CREDIT_INCOME_RATIO'] = X_val['AMT_CREDIT'] / X_val['AMT_INCOME_TOTAL']\n",
        "X_val['EMPLOYED_AGE_RATIO'] = X_val['DAYS_EMPLOYED'] / X_val['DAYS_BIRTH']\n",
        "X_val['ANNUITY_INCOME_RATIO'] = X_val['AMT_ANNUITY'] / X_val['AMT_INCOME_TOTAL']\n",
        "\n",
        "features_2 = ['CREDIT_INCOME_RATIO', 'EMPLOYED_AGE_RATIO', 'ANNUITY_INCOME_RATIO']\n",
        "pipeline_2 = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "model_2 = pipeline_2.fit(X_train[features_2], y_train)\n",
        "auc_2 = evaluate_model(model_2, X_val[features_2], y_val)\n",
        "\n",
        "# Pattern 3: External Source Aggregates\n",
        "for df in [X_train, X_val]:\n",
        "    df['EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
        "    df['EXT_SOURCES_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
        "\n",
        "features_3 = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'EXT_SOURCES_MEAN', 'EXT_SOURCES_STD']\n",
        "pipeline_3 = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "model_3 = pipeline_3.fit(X_train[features_3], y_train)\n",
        "auc_3 = evaluate_model(model_3, X_val[features_3], y_val)\n",
        "\n",
        "# Pattern 4: Polynomial Interactions\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "ext_train = imputer.fit_transform(X_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']])\n",
        "ext_val = imputer.transform(X_val[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']])\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "X_poly_train = poly.fit_transform(ext_train)\n",
        "X_poly_val = poly.transform(ext_val)\n",
        "\n",
        "model_4 = LogisticRegression(max_iter=1000)\n",
        "model_4.fit(X_poly_train, y_train)\n",
        "auc_4 = evaluate_model(model_4, X_poly_val, y_val)\n",
        "\n",
        "# Pattern 5: Categorical + Numeric Mix\n",
        "cat_features = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'NAME_EDUCATION_TYPE']\n",
        "num_features = ['AMT_CREDIT', 'DAYS_BIRTH', 'EXT_SOURCE_2']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), num_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
        "])\n",
        "\n",
        "pipeline_5 = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "model_5 = pipeline_5.fit(X_train[cat_features + num_features], y_train)\n",
        "auc_5 = evaluate_model(model_5, X_val[cat_features + num_features], y_val)\n",
        "\n",
        "# Results\n",
        "print(f'Pattern 1 AUC: {auc_1:.3f}')\n",
        "print(f'Pattern 2 AUC: {auc_2:.3f}')\n",
        "print(f'Pattern 3 AUC: {auc_3:.3f}')\n",
        "print(f'Pattern 4 AUC: {auc_4:.3f}')\n",
        "print(f'Pattern 5 AUC: {auc_5:.3f}')\n",
        "\n",
        "# Final Submission\n",
        "test['EXT_SOURCE_2'] = test['EXT_SOURCE_2'].fillna(test['EXT_SOURCE_2'].median())\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
        "    'TARGET': pipeline_5.predict_proba(test[cat_features + num_features])[:, 1]\n",
        "})\n",
        "submission.to_csv('final_submission.csv', index=False)\n",
        "print(\"✅ Submission saved as final_submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEt6ALOaUoLi",
        "outputId": "51d27e05-9536-43a4-bcde-1c93f92fbdaf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pattern 1 AUC: 0.592\n",
            "Pattern 2 AUC: 0.566\n",
            "Pattern 3 AUC: 0.721\n",
            "Pattern 4 AUC: 0.719\n",
            "Pattern 5 AUC: 0.630\n",
            "✅ Submission saved as final_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "I explored five distinct feature engineering strategies to improve model accuracy on the Home Credit Default Risk dataset. Each pattern involved different combinations of features and preprocessing techniques:\n",
        "\n",
        "| Pattern | Strategy                    | Validation AUC |\n",
        "|---------|-----------------------------|----------------|\n",
        "| 1️⃣      | Basic numeric features       | 0.592          |\n",
        "| 2️⃣      | Ratio-based features         | 0.566          |\n",
        "| 3️⃣      | External source aggregates   | 0.721          |\n",
        "| 4️⃣      | Polynomial interactions      | 0.719          |\n",
        "| 5️⃣      | Categorical + numeric mix    | 0.630          |\n",
        "\n",
        "\n",
        "Pattern 3 leverages the power of three external credit scoring features—EXT_SOURCE_1, EXT_SOURCE_2, and EXT_SOURCE_3—which are known to be highly predictive of loan default risk. By enriching these with:\n",
        "\n",
        "(EXT_SOURCES_MEAN: captures the average creditworthiness signal\n",
        "\n",
        "EXT_SOURCES_STD: reflects variability across sources)\n",
        "\n",
        "the model gains a more nuanced view of applicant reliability.\n",
        "\n",
        "Combined with a clean preprocessing pipeline and a well-calibrated Logistic Regression, this setup delivers the highest AUC score on the validation set—indicating strong generalization and predictive power."
      ],
      "metadata": {
        "id": "fneA2484Y7qQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading the final_submission.csv file to submit on Kaggle**"
      ],
      "metadata": {
        "id": "2HrfGCb6bOOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"final_submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BSrJMgY_bMXN",
        "outputId": "eb4acab0-08b6-495a-ae6b-7f4d9c215c2c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12e7deda-c3a2-45ea-8d03-6ce9fddf2d91\", \"final_submission.csv\", 577549)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}